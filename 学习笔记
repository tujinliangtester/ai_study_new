
++++++++++++++++++++++++++++++++++++++++++++++++++
从20190312开始，笔记都记在qq空间上
++++++++++++++++++++++++++++++++++++++++++++++++++

各种图片、NPL、语音识别数据集：
https://blog.csdn.net/haoji007/article/details/81020256


思想很重要，算法是实现思想，得出结果，实现必须执行
tf：
1.首先画出计算图
2.图的每一个节点构建，可能是constant，可能是varible，可能是placeholder
3.在图中使用解决思想的优化方法，进行迭代
4.真正在session中,给数据并进行计算，得出结果
5.评估结果，当结果相差甚远的时候，有两种思路，从根往叶找，或从叶往根找。在此之前，首先应将优化算法相关的东西全部砍掉！
    所以，步骤应为：
        1.逐步砍掉优化算法
        2.模型是否正确
        3.构建图是否正确
        4.数据是否正确
        5.计算是否正确
        6.评估是否正确
6.保存模型
    创建saver节点，    saver=tf.train.Saver()
    其实就是保留的Variable和迭代情况，可以直接保存session
    调用模型时直接用saver的restore方法，将模型赋值给当前session，
    注意，这里还是需要构建图，其他操作与训练时一致，只是无需再训练了
7.代码模块化
    将重复代码抽象成函数进行调用即可
8.tensorboard
    tf.summary.scalar  标量，记录的是每一步时的值，注意此标量不能是矩阵或向量
    tf.summary.histogram 柱状图，可以记录每一步时的矩阵或向量取值
    tf.summary.merge_all 将各个视图进行合并，统一进行记录及展示,
                            注意，这里的merge_all会返回一个对象，
                            需要在tf.session中run这个merge后的对象，
                            得到的结果，用下面的FileWriter写入到目录中
                            fw.add_summary(summary=summary_str,global_step=n)
    tf.summary.FileWriter('logs/',sess.graph)  将图表输出到目录



在计算cifar的时候，深感体会数据的重要性：
	1.首先是数据的获取，如果是第三方的数据，一定要按照官方的说明进行读取、使用
	2.对数据的结构一定要全面了解，包括分布、组织方式等，否则对后续的模型计算、模型评估有很大影响！
	
梯度反向传播，其实就是数学计算在计算机上的实现（思路还是最核心的）


生成对抗网络（无监督机器学习）（课程中介绍是从物种与天敌的相互进化的规律得来的）
分为生成和对抗两步
	首先是生成，但是在无监督机器学习中是没有label的，那么就无法判断这个生成究竟是好还是坏，进一步的无法得到loss，也就无从训练。此时，如何评价这个输出结果成了问题。
	那么，能不能用户深度学习来进行评估？即重新构造一个网络来判定，这个输出结果是不好的（一般情况都是这样），而真实事物，或者叫已知正确的事物的评估结果是好的
	所以，对抗模型训练好之后，就可以再回过头来训练生成模型。
	如此循环迭代，最终会使得生成网络的输出结果越来越接近真实的或正确的。
	(学习暂缓，先学习NLP)
	



语音识别：
1.声音的叠加
	如何拆分声音的叠加？
	声音有三要素，频率、音量、音色。
	应该是根据音色来拆分。如何得出音色？
2.仿生，人在学习、认知声音的过程，是将听觉与视觉结合起来的。
	视觉就是图片，视频就是图片的变化。
	怎么讲声音和图片结合起来？怎样将声音与图片的变化结合起来？
	可不可以将声音识别与一个训练完成的图片模型结合起来？先是视觉认知图片，然后在视觉的基础上加上声音认知图片，最后再直接用声音认知来判定具体的图片
	图片是多通道的二维数组，声音是什么呢？
	仿生学有时候是可以简化问题，但有时候又需要进行取舍。先还是按照小孩子学习的教程来进行。

语音识别新思路，不要过于拘泥于某个音或某个单词，而应该学习机器翻译的思维，直接听一句话，再进行语音识别，这样就比
    单独识别字母、单词有非常高的上限优越性，同时，在处理单个单词的识别时，也完全能达到要求。但这是之前没有看到教程的
    可能会失败，需要用实践进行检验




处理语言识别，需要先学习RNN
1.RNN的思想是非常重要的，就是前面的结果需要影响后面的结果，给一个模型，将前一个输出作为下一个的输入中的一部分。
2.对于梯度消失，RNN中，可以理解为前面对后面的影响减弱，一种思路是门开关的思想，将前一个输出打开或关闭，从而影响后面的计算，即GRU
	另外一种是LSTM，其实这也是一种门开关的思想，只是比GRU更加复杂一些，可以控制的也更灵活、更多一些。
3.BRNN（bidirectional RNN）
	可以通过后续的结果来反过来判断前一个结果到底是什么
4.Deep RNN
	每个单独的序列层上，考虑deep 层，既考虑了序列时间，又考虑了深度
	（当然，由于模型可能越来越大，后面的层可以考虑只看深度层或只看时间序列层）
5.在介绍word representation时，提到了两个单词之间的相关性，用one hot编码的话，任意两个单词都是不相关的，知识图谱会有用吗？
	教材中是用了特征来对单词进行编码，从而可以计算单词间的相关性

RNN
    下面是构建rnn时，官方的方法
    from tensorflow.contrib import legacy_seq2seq
    legacy_seq2seq.rnn_decoder：
  with variable_scope.variable_scope(scope or "rnn_decoder"):
    state = initial_state
    outputs = []
    prev = None
    for i, inp in enumerate(decoder_inputs):
      if loop_function is not None and prev is not None:
        with variable_scope.variable_scope("loop_function", reuse=True):
          inp = loop_function(prev, i)
      if i > 0:
        variable_scope.get_variable_scope().reuse_variables()
      output, state = cell(inp, state)
      outputs.append(output)
      if loop_function is not None:
        prev = output
  return outputs, state

    其中：loop_function是个循环函数
            def loop(prev, _):
            prev = tf.matmul(prev, softmax_w) + softmax_b
            prev_symbol = tf.stop_gradient(tf.argmax(prev, 1))
            return tf.nn.embedding_lookup(embedding, prev_symbol)
    从上面可以看出，其实还是循环的思想，但是这里只有decoder，没有找到encoder，其实可以仿照的来生成？
    用笔和纸对上面的代码进行了分析
        1.分析出很多问题，需要后续进行解决
        2.需要想办法将图形的笔记整理处理，可能需要一个很好的笔记工具，但是不能跟项目代码放在一起


TensorFlow：
	https://www.tensorflow.org/tutorials/audio_recognition
	
在TensorFlow的练习中，optimizer文件，对房价进行线性回归时，mse不降反升
    而用adam方法进行计算时，模型正常，有可能是因为记录数量太大了，导致在计算的过程中数据溢出
    用SGD或mini batch GD可能会正常，（实验证明，不行）


RNN
    今天终于通过别人的代码，看到了rnn应该是个什么样子了。。。
    需要好好研究下tensorflow.contrib.rnn.static_rnn以及 tf.nn.rnn_cell.BasicLSTMCell等中的代码，看看具体是怎么实现的
    rnn及lstm的模型可以复习下Andrew的内容
    通过tensorboard能看到别人代码的graph，现在的问题是，怎么才能构建自己的模型？或者说，怎么才能构建decoder？可以进行构建

    音频文件已经转换成.npy文件


为什么要进行批标准化？
按照教程的说法，是为了使数据进入激活函数，如softmax等时，均匀分布在0两侧，这样激活后的分类效果更好
又由于批标准化一般都是进行标准状态分布的处理，会导致过于集中在0附近，在激活函数后值可能还不是因为丧失了非线性特征
因为有些激活函数本身就是分段线性的，比如relu
个人感觉应该是因为过于靠近0，导致激活分类的值较为接近，增加了缩放因子和偏移因子后，训练的分类结果会更加明显

怎么能想到进行批标准化？可能还是因为仔细研究了训练过程，发现了过程中的一些数据分布存在异常，
但是如果直接keras等框架的话，是没有办法做到这么细致的，所以很多地方还是需要手动一步步的实现、研究
怎么能想到加缩放因子和偏移因子？估计也是与上面的类似，比如遇到的结果之间太过接近，从而导致训练结果不好
增加了缩放和偏移并进行训练后，能够到达不错的效果

刚刚突然想到，这些都不是仿生来的？那么作为生物的人是怎么来进行训练、识别的呢？生物中的激活函数是怎么实现的？
还是说大脑有存量数据在，不完全是计算的结果？有可能会计算视图与存量之间的关联性，
就好比，对图片有一个网络运算后的结果，这个结果与某些图片运算后的结果相似，
实际上就是去掉了后面的一些网络层及逻辑处理，
这可能还不仅仅是一个层数的问题，我觉得还有可能是发散作用，而不仅仅是特征提取作用了
但是对于计算机而言，没有了loss函数，没有办法进行计算和优化
另外，除了交叉熵、均方误差外，还有没有其他的loss函数？如果能找到更接近、类似的loss函数的话，可能效果更好

经典模型lenet alexnet等
到底卷积核该用几个？CBAPD该不该选用？取值应是怎样？需要几次卷积？几次全连接？
是胡乱猜出来的吗？也许不是

inception结构块，核心是在同一层使用不同尺寸的卷积核，可以提取不同的特征
在深度上进行叠加，以保持原图信息
而resnet是直接将网络抽象值与原图的值进行相加
resnet的做法让我想到了模拟人的学习方法，比如这就有点像及时复习
根据以往的经验，复习确确实实是非常好的学习方法，对逻辑、形象等的重复，有助于学习理解、消化、吸收
甚至跟大脑复习很像的是，复习不完全是重复走初次学习的路径，可能会有一些跳跃，但这些跳跃在某种意义上说是科学的
大脑的学习方法包括：
及时复习：
    实验给出的建议是5分钟后重复一遍，20分钟后再重复一遍，1小时后，12小时后，1天后，2天后，5天后，8天后，14天后就会记得很牢，很难再遗忘。
    可能可以用层数来类比时间
记忆编码理论：必须动手构建知识树
    实际上就是将所有的知识融会贯通，形成体系，就好比听觉、触觉在某种程度上会有助于视觉方面的学习
    或许像谷歌大脑、百度大脑就是有这种思想，比如将图形识别、语言识别、NLP等各种训练结合起来
    或者某些层可以是公用的基础层？
合理休息，休息也是学习的一种
    这个怎么运用到神经网络呢？dropout是不是有点类似？
记笔记：
    其实就是一些中间或后端学习产物，复习笔记就是将这些产物再次运行起来，这么说来也有点像resnet的做法
    或者，在最后，将这些中间产物（层）再次集中运算？


另外，科学是需要灵感的，神经网络需要灵感吗？

另外，人脑分左右脑，分别控制逻辑和想象，神经网络感觉更偏想象一些，
如果对数据预先进行一些逻辑处理，再交给神经网络，会不会有更好的效果？

另外，大脑分左右脑，分别处理逻辑和想象，有时候，想象比逻辑更为重要，那么神经网络是什么呢？其实可能更偏想象一些？但又感觉是逻辑处理运算的
所以，用逻辑运算来实现想象功能，本身是不是就南辕北辙了？

可以不通过卷积来图像识别吗？ps这些软件，识别的时候是通过颜色阈值，
其实是不是应该先将图片变成简笔画，然后再进行识别？毕加索？
增加对比度的原理是什么？
有时候会觉得这样的训练方式有问题，比如小孩子在学习识别数字的时候，最开始肯定是标准的写法图片
不应该增加卷积核，难道因为训练参数过多就得用卷积核这种吗？
还是因为仿生的方式，多层，逐级传播。但这又有个问题了，梯度消失怎么解决？
还有个问题，生物上是怎么处理二维、三维的？眼睛的细胞是一圈平面，那有没有办法构造类似的神经网络？
而且，一般人都是两个眼睛，虽然说在3D方面有优势，但是对于2D平面有没有帮助？
对了，其实是有帮助的，聚焦！
目前的这些神经网络，还都是拉直的，有没有对应一个平面的神经网络？真正的网络？

突然想到一个问题，人脑在识别的时候，传输的过程中有进行处理吗？实际上各神经传输的时候，值都是一样的？
那么信号传到大脑的时候，是怎么处理的呢？

始终都没有得到好的效果，最多也就80%左右的准确率，所以在考虑要不要从结构上进行改变
基于仿生学，大脑是网格的，还是立体的？即是三维的？还是更多维的？
尝试一下多维吧，比如三维/四维等
怎么搭建呢？
好像框架不支持？
虽然手动实现了多维网络，但经过分析和试验，得出结论：没有用，当然也可能是想的和做出来的不一样

接下来需要做两个试验：
1.类比左右眼，不仅仅是角度、位置的区别，人脑视觉处理也是分左右脑来处理两只眼睛的，
    所以构建两个模型是值得试验的
    甚至可以考虑多个不同的模型，参考随机森林，数量多的那个可能准确率会更高
2.由于人眼感知，是靠光的波长来识别颜色的，并不是解析成三原色，
    那么，经过思考，将三通道换算成单通道，是更符合实际现实的，同时也会有模型准确率上的理论提升

    其实这就是RGB转灰度图。。。试验一下吧

经过试验2，转灰度并没有提升
还是尝试一下试验1吧，将之前的所有分析，包括resnet inceptionnet jump 等都用上，加上图片的处理  RGB 反转RGB 灰度图等
但是试验1太不人工智能了，但有没有可能，人脑其实也是多个不同的机制在同时判定，所以才会有矛盾存在？
还是先做吧。
但是回想起视频教程里老师说过，准确率达到90%以上才去交流，那证明是完全有可能的
只是目前暂时没有灵感了，有灵感了再继续尝试

今天看到一篇文章讲GNN，说到了点与周围节点的影响，这其实是有道理的，但是他整篇的各种理论我不喜欢
因为人脑没有这些理论啊，但是人脑的智慧却远远超过了文章中的内容
那么应该说人脑也会处理点与周围点的关系，虽然说神经网络在计算中，各个点之间是会相互产生影响的，但影响滞后了，应该会影响准确率
虽然CNN有计算，但仅仅只是加和，可能与实际人脑的结构模型不符，又回到这个问题了，人脑的神经元之间到底是什么结构？
大脑是不是有脑水的概念，包括有些动图里面大脑神经元都是会动态变化的，那么如果在神经网络中增加类似的作用呢？
