
各种图片、NPL、语音识别数据集：
https://blog.csdn.net/haoji007/article/details/81020256


思想很重要，算法是实现思想，得出结果，实现必须执行
tf：
1.首先画出计算图
2.图的每一个节点构建，可能是constant，可能是varible，可能是placeholder
3.在图中使用解决思想的优化方法，进行迭代
4.真正在session中,给数据并进行计算，得出结果
5.评估结果，当结果相差甚远的时候，有两种思路，从根往叶找，或从叶往根找。在此之前，首先应将优化算法相关的东西全部砍掉！
    所以，步骤应为：
        1.逐步砍掉优化算法
        2.模型是否正确
        3.构建图是否正确
        4.数据是否正确
        5.计算是否正确
        6.评估是否正确
6.保存模型
    创建saver节点，其实就是保留的Variable和迭代情况，可以直接保存session
    调用模型时直接用saver的restore方法，将模型赋值给当前session，
    注意，这里还是需要构建图，其他操作与训练时一致，只是无需再训练了
7.代码模块化
    将重复代码抽象成函数进行调用即可
8.tensorboard
    tf.summary.scalar  标量，记录的是每一步时的值，注意此标量不能是矩阵或向量
    tf.summary.histogram 柱状图，可以记录每一步时的矩阵或向量取值
    tf.summary.merge_all 将各个视图进行合并，统一进行记录及展示,
                            注意，这里的merge_all会返回一个对象，
                            需要在tf.session中run这个merge后的对象，
                            得到的结果，用下面的FileWriter写入到目录中
                            fw.add_summary(summary=summary_str,global_step=n)
    tf.summary.FileWriter('logs/',sess.graph)  将图表输出到目录



在计算cifar的时候，深感体会数据的重要性：
	1.首先是数据的获取，如果是第三方的数据，一定要按照官方的说明进行读取、使用
	2.对数据的结构一定要全面了解，包括分布、组织方式等，否则对后续的模型计算、模型评估有很大影响！
	
梯度反向传播，其实就是数学计算在计算机上的实现（思路还是最核心的）


生成对抗网络（无监督机器学习）（课程中介绍是从物种与天敌的相互进化的规律得来的）
分为生成和对抗两步
	首先是生成，但是在无监督机器学习中是没有label的，那么就无法判断这个生成究竟是好还是坏，进一步的无法得到loss，也就无从训练。此时，如何评价这个输出结果成了问题。
	那么，能不能用户深度学习来进行评估？即重新构造一个网络来判定，这个输出结果是不好的（一般情况都是这样），而真实事物，或者叫已知正确的事物的评估结果是好的
	所以，对抗模型训练好之后，就可以再回过头来训练生成模型。
	如此循环迭代，最终会使得生成网络的输出结果越来越接近真实的或正确的。
	(学习暂缓，先学习NLP)
	



语音识别：
1.声音的叠加
	如何拆分声音的叠加？
	声音有三要素，频率、音量、音色。
	应该是根据音色来拆分。如何得出音色？
2.仿生，人在学习、认知声音的过程，是将听觉与视觉结合起来的。
	视觉就是图片，视频就是图片的变化。
	怎么讲声音和图片结合起来？怎样将声音与图片的变化结合起来？
	可不可以将声音识别与一个训练完成的图片模型结合起来？先是视觉认知图片，然后在视觉的基础上加上声音认知图片，最后再直接用声音认知来判定具体的图片
	图片是多通道的二维数组，声音是什么呢？
	仿生学有时候是可以简化问题，但有时候又需要进行取舍。先还是按照小孩子学习的教程来进行。

语音识别新思路，不要过于拘泥于某个音或某个单词，而应该学习机器翻译的思维，直接听一句话，再进行语音识别，这样就比
    单独识别字母、单词有非常高的上限优越性，同时，在处理单个单词的识别时，也完全能达到要求。但这是之前没有看到教程的
    可能会失败，需要用实践进行检验



NLP学习：


处理语言识别，需要先学习RNN
1.RNN的思想是非常重要的，就是前面的结果需要影响后面的结果，给一个模型，将前一个输出作为下一个的输入中的一部分。
2.对于梯度消失，RNN中，可以理解为前面对后面的影响减弱，一种思路是门开关的思想，将前一个输出打开或关闭，从而影响后面的计算，即GRU
	另外一种是LSTM，其实这也是一种门开关的思想，只是比GRU更加复杂一些，可以控制的也更灵活、更多一些。
3.BRNN（bidirectional RNN）
	可以通过后续的结果来反过来判断前一个结果到底是什么
4.Deep RNN
	每个单独的序列层上，考虑deep 层，既考虑了序列时间，又考虑了深度（当然，由于模型可能越来越大，后面的层可以考虑只看深度层或只看时间序列层）
5.在介绍word representation时，提到了两个单词之间的相关性，用one hot编码的话，任意两个单词都是不相关的，知识图谱会有用吗？
	教材中是用了特征来对单词进行编码，从而可以计算单词间的相关性



TensorFlow：
	https://www.tensorflow.org/tutorials/audio_recognition
	
在TensorFlow的练习中，optimizer文件，对房价进行线性回归时，mse不降反升
而用adam方法进行计算时，模型正常，有可能是因为记录数量太大了，导致在计算的过程中数据溢出
用SGD或mini batch GD可能会正常，实验证明，不行


RNN
    今天终于通过别人的代码，看到了rnn应该是个什么样子了。。。
    需要好好研究下tensorflow.contrib.rnn.static_rnn以及 tf.nn.rnn_cell.BasicLSTMCell等中的代码，看看具体是怎么实现的
    rnn及lstm的模型可以复习下Andrew的内容
    通过tensorboard能看到别人代码的graph，现在的问题是，怎么才能构建自己的模型？或者说，怎么才能构建decoder？可以进行构建

    音频文件已经转换成.npy文件


	